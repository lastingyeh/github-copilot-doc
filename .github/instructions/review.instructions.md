---
applyTo: '**'
---
# AI 軟體系統開發產出評估指南

## 目的與範圍
本指南協助技術人員快速且有效地評估 AI 產出的軟體系統開發內容，確保產出品質與一致性。

## 評估流程總覽

### 1. 任務理解評估
檢查 AI 是否正確理解開發任務：
- **需求理解度**：AI 是否準確解析業務需求與技術規格
- **架構決策**：所選擇的技術棧與架構模式是否符合專案要求
- **範圍界定**：是否正確識別開發範圍與邊界條件

### 2. 執行步驟檢核
評估 AI 執行開發任務的步驟：
- **步驟完整性**：是否包含必要的開發階段（分析、設計、實作、測試）
- **邏輯順序**：各步驟之間的依賴關係是否合理
- **里程碑設置**：是否設定適當的檢查點與驗證標準

### 3. 產出檔案評估

#### 3.1 程式碼品質檢核
- **架構符合性**：是否遵循 Clean Architecture 原則
- **編碼規範**：符合 Google Java Style 與命名慣例
- **測試覆蓋**：包含單元測試與整合測試
- **文件完整性**：JavaDoc 與技術文件是否齊全

#### 3.2 設定檔案檢核
- **Docker 組態**：Dockerfile 與 docker-compose.yml 正確性
- **資料庫遷移**：Liquibase changelog 檔案完整性
- **環境變數**：所有必要的組態項目是否可透過環境變數設定
- **監控組態**：Actuator 端點與 Prometheus 指標設定

#### 3.3 文件品質檢核
- **README 完整性**：包含系統架構圖、啟動指南、環境變數說明
- **API 文件**：SpringDoc 註解完整，Swagger UI 可正常存取
- **變更記錄**：Changelog 與 Git commit 訊息符合規範

## 異動檔案追蹤與說明

### 檔案分類標準
根據異動類型將檔案分類：

#### 核心業務邏輯
- `domain/` - 領域模型與商業規則
- `application/` - Use Cases 與應用服務
- **評估重點**：業務邏輯正確性、領域模型設計

#### 介面層
- `adapters/web/` - REST Controllers 與 Web DTOs
- `adapters/messaging/` - 訊息處理器
- **評估重點**：輸入驗證、錯誤處理、OpenAPI 文件

#### 基礎設施層
- `infrastructure/persistence/` - 資料持久化實作
- `infrastructure/config/` - Spring 組態設定
- **評估重點**：效能優化、安全性設定

#### 測試檔案
- `src/test/` - 所有測試相關檔案
- **評估重點**：測試覆蓋率、測試場景完整性

### 異動說明格式
每個異動檔案需包含以下說明：
```markdown
### 檔案路径：`src/main/java/com/example/orders/domain/model/Order.java`
- **異動類型**：新增/修改/刪除
- **變更原因**：業務需求變更/效能優化/錯誤修正
- **影響範圍**：相關檔案與功能模組
- **驗證方式**：單元測試/整合測試/手動驗證
```

## 產出紀錄儲存設計

### 紀錄結構
每次 AI 產出建立獨立的評估紀錄：

```yaml
# .ai-review-logs/YYYY-MM-DD-HH-mm-ss-task-summary.md
評估紀錄:
  任務識別碼: "TASK-2024-001"
  評估時間: "2024-09-15T10:30:00Z"
  評估人員: "reviewer-name"
  AI 模型: "GitHub Copilot"

任務概述:
  需求描述: "新增訂單管理功能"
  預期產出: "REST API + 資料模型 + 測試"

執行步驟評估:
  步驟完整性: "✓ 通過"
  邏輯順序: "✓ 通過"
  里程碑設置: "⚠ 需改進"

產出檔案清單:
  - path: "src/main/java/com/example/orders/domain/model/Order.java"
    type: "新增"
    status: "✓ 通過"
    issues: []

品質評估:
  架構符合性: "✓ 通過"
  編碼規範: "✓ 通過"
  測試覆蓋: "⚠ 需改進"
  文件完整性: "✓ 通過"

改進建議:
  - "增加邊界條件測試案例"
  - "補充 Redis 快取失效機制說明"

總體評分: "85/100"
審查狀態: "通過（有條件）"
```

### 儲存策略
- **檔案命名**：`YYYY-MM-DD-HH-mm-ss-task-summary.md`
- **目錄結構**：`.ai-review-logs/YYYY/MM/`
- **索引檔案**：`index.md` 提供快速檢索
- **保留期限**：保留 12 個月的評估紀錄

### 統計分析
定期產生評估統計報告：
- **通過率趨勢**：不同時期的產出品質變化
- **常見問題**：重複出現的品質問題分析
- **改進建議**：基於歷史數據的優化建議

## 快速檢核清單

### 開發前檢核
- [ ] 需求理解正確
- [ ] 技術選型合理
- [ ] 架構設計符合規範

### 實作中檢核
- [ ] 程式碼符合編碼規範
- [ ] 測試案例涵蓋主要場景
- [ ] 錯誤處理機制完整

### 交付前檢核
- [ ] 所有測試通過
- [ ] 文件更新完整
- [ ] 監控端點正常運作
- [ ] Docker 容器成功建置

## 評估標準與評分機制

### 評分維度
1. **功能正確性**（30%）：功能實作是否符合需求
2. **程式碼品質**（25%）：架構設計與編碼規範遵循度
3. **測試完整性**（20%）：測試覆蓋率與測試品質
4. **文件品質**（15%）：技術文件與註解完整性
5. **維運準備**（10%）：監控、日誌、部署組態完整性

### 評分標準
- **優秀（90-100分）**：可直接上線，無需修改
- **良好（80-89分）**：輕微調整後可上線
- **及格（70-79分）**：需要適度修改
- **不及格（<70分）**：需要重大修改或重新開發